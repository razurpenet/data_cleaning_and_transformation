# data_cleaning_and_transformation

## Task
The previous data engineer often keep logs of the details of previously 
executed pipelines triggered by their orchestration tool 

As a new Engineer on the team, i have to know and understand the functions and
processes carried out as documentaed in the log 

## Tools
Pandas<br>
Git

## File
log.txt

## Schema

task: The task performed by the executed function<br>
status: The execution status<br>
trackerID: The executionID used to track these functions<br>
serverregion: The location of the server on which the said function was executed<br>
timestamp: The time the function was executed<br>
server: The IP address of the server on which the said function was executed